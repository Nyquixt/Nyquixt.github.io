---
title: "CoConv: Learning Dynamic Cooperative Convolution for Image Recognition"
collection: publications
category: conferences
permalink: /publication/2021-icme
excerpt: "<b>Abstract.</b> In this paper, we present a conceptually simple, yet powerful method for image recognition. The method, called Cooperative Dynamic Convolution (CoConv), introduces a cooperative learning of dynamic convolution from multiple convolutional experts. CoConv can be used as a substitute for the traditional static convolution, and can be seamlessly integrated in various visual models. Moreover, CoConv is easy to train with only a minimal computational overhead introduced in the inference phase. CoConv is trained by using multiple convolutional experts simultaneously, and the convolutional weights are merged by a weighted summation before convolutional operations for efficiency during inference. Results from extensive experiments show that CoConv leads to consistent improvement for image classification on various datasets, independent of the choice of the base convolutional network. Remarkably, CoConv improves the top-1 classification accuracy of ResNet18 by 3.06% on ImageNet."
date: 2021-07-01
venue: 'International Conference on Multimedia & Expo (Oral)'
# slidesurl: 'http://nyquixt.github.io/files/icme-slides.pdf'
paperurl: 'http://nyquixt.github.io/files/icme21-paper.pdf'
bibtexurl: 'http://nyquixt.github.io/files/icme21-bibtex.bib'
citation: '<b>Kien X. Nguyen</b>, Tiffany Ryu, Jocelyn Zhang, Xu Ma, Qing Yang, Song Fu, Paparao Palacharla, Nannan Wang, and Xi Wang. &quot;CoConv: Learning Dynamic Cooperative Convolution for Image Recognition.&quot; <i>In IEEE International Conference on Multimedia & Expo</i>, 2021.'
---
<b>Abstract.</b> In this paper, we present a conceptually simple, yet powerful method for image recognition. The method, called Cooperative Dynamic Convolution (CoConv), introduces a cooperative learning of dynamic convolution from multiple convolutional experts. CoConv can be used as a substitute for the traditional static convolution, and can be seamlessly integrated in various visual models. Moreover, CoConv is easy to train with only a minimal computational overhead introduced in the inference phase. CoConv is trained by using multiple convolutional experts simultaneously, and the convolutional weights are merged by a weighted summation before convolutional operations for efficiency during inference. Results from extensive experiments show that CoConv leads to consistent improvement for image classification on various datasets, independent of the choice of the base convolutional network. Remarkably, CoConv improves the top-1 classification accuracy of ResNet18 by 3.06% on ImageNet.
